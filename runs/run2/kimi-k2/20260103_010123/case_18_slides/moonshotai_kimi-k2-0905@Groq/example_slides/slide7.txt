Cross-Validation Techniques
============================
K-Fold Cross-Validation:
- Split data into k equal parts
- Train on k-1 parts, test on 1 part
- Repeat k times, average results

Stratified K-Fold:
- Maintains class distribution
- Better for imbalanced datasets

Leave-One-Out:
- Special case of k-fold where k=n
- Maximum use of data
- Computationally expensive